<HTML><HEAD><TITLE>Le myst&egrave;re de la chambre chinoise</TITLE></HEAD>
<BODY>
	<H3>Le myst&egrave;re de la chambre chinoise</H3><br>
<br>
	Les ordinateurs peuvent-ils comprendre ? C'est ce qu'on pourrait penser &agrave; la lumi&egrave;re des r&eacute;cents d&eacute;veloppements de l'intelligence artificielle. Un programme &eacute;crit par Roger Schank est capable de r&eacute;pondre &agrave; des questions concernant des histoires simples. (scripts, plans, goals and understanding). Mais ce programme comprend-t-il r&eacute;ellement ces histoires ou simule-t-il seulement la compr&eacute;hension ? <br>
	Pour tenter de r&eacute;pondre &agrave; cette question, le philosophe am&eacute;ricain John Searle imagine la situation suivante:<br>
	Il est enferm&eacute; dans une chambre dans laquelle on lui glisse l'histoire et les questions en chinois &agrave; travers une fente. Il ne comprend rien au chinois mais il dispose des instructions exactes, r&eacute;dig&eacute;es en Anglais, permettant de d&eacute;terminer les r&eacute;ponses. Il fait donc la m&ecirc;me chose que le programme de Schank, et ne comprend rien aux histoires. Searle en d&eacute;duit donc que le programme de Schank ne comprend rien non plus aux histoires.<br>
	Plusieurs objections ont &eacute;t&eacute; soulev&eacute;es par cette d&eacute;monstration et la plus convaincante me para&icirc;t &ecirc;tre celle selon laquelle si Searle lui-m&ecirc;me ne comprend rien aux histoires, de son activit&eacute; de manipulation de symboles chinois &eacute;merge une sorte d'entit&eacute; (le chinois simul&eacute; par Searle) bien distincte de Searle, bien que r&eacute;sultant de son activit&eacute;, et qui, elle, comprend les histoires. De m&ecirc;me, quand nous comprenons une histoire, nos neurones, consid&eacute;r&eacute;s en tant que petits &ecirc;tres vivants, n'y comprennent rien, tout ce qu'ils font est de r&eacute;agir aux excitations transmises par les autres neurones; mais de cette activit&eacute; &eacute;merge l'esprit humain qui, lui, comprend l'histoire.<br>
<br>
	Il apparait donc que si l'on prend le mot "comprendre" dans un sens faible, ext&eacute;rieur, comportemental, les ordinateurs peuvent comprendre. Mais le mot "comprendre" peut aussi &ecirc;tre pris dans un sens plus fort, int&eacute;rieur, de compr&eacute;hension consciente, et c'est le point de vue adopt&eacute; par Searle. Mais le probl&egrave;me est qu'il supose abusivement que c'est l&agrave; le seul sens su mot "comprendre", alors que les partisans de l'intelligence artificielle "forte" au contraire consid&egrave;rent que la compr&eacute;hension se d&eacute;finit uniquement de fa&ccedil;on externe, comportementale, d'o&ugrave; le d&eacute;saccord. Le probl&egrave;me philosophique est donc doubl&eacute; d'un probl&egrave;me s&eacute;mantique. L'apparition de l'intelligence artificielle a provoqu&eacute; une "ramification s&eacute;mantique" du concept de compr&eacute;hension ("brisure de sym&eacute;trie"). Avant, la compr&eacute;hension comportementale et la compr&eacute;hension conscient &eacute;taient li&eacute;s, il n'y avait donc pas besoin de deux mots diff&eacute;rents pour d&eacute;signer ces deux concepts qui sont pourtant bien diff&eacute;rents. Mais maintenant, il me semble qu'il n'y a pas de raison de privil&eacute;gier un sens par rapport &agrave; l'autre, et que quand on parle de compr&eacute;hension, pour &ecirc;tre pr&eacute;cis on devrait toujours pr&eacute;ciser s'il s'agit de compr&eacute;hension comportementale ou consciente.<br>
	Apr&egrave;s avoir pr&eacute;cis&eacute; les choses d'un point de vue s&eacute;mantique, il reste certaines questions philosophiques et m&eacute;taphysiques fondamentales : l'ordinateur comprend-il au sens conscient ? Et l'entit&eacute; qui &eacute;merge de l'activit&eacute; de Searle dans sa chambre chinoise ? La compr&eacute;hension consciente d&eacute;coule-t-elle de la compr&eacute;hension comportementale ?<br>
	Personnellement, je doute que la conscience puisse &eacute;merger d'un processus mettant en jeu un nombre de r&egrave;gles fini et bien d&eacute;finies. Je pense plut&ograve;t qu'elle apparait ainsi que le libre arbitre dans le cas o&ugrave; on a un processus limite d'une suite infinie de processus d&eacute;finis pr&eacute;cis&eacute;ment de fa&ccedil;on finie et qui constituent des approximations successives de plus en plus pr&eacute;cises mais jamais rigoureusement exactes, du processus duquel &eacute;mergent alors &agrave; la fois la conscience et le libre arbitre.<br>
<br>

</BODY></HTML>
